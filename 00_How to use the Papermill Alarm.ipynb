{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1179983a",
   "metadata": {},
   "source": [
    "## How to use the Papermill Alarm\n",
    "\n",
    "The Papermill Alarm is a simple API which receives a title and abstract from you and which returns a prediction of whether the paper _looks like_ it came from a papermill. It's important to keep in mind that, just because a paper _looks like_ a papermill-product, this does not mean that it is one. \n",
    "\n",
    "Let's start with the basics. We'll import the requests package which will do the majority of the work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efe958cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e5f4e",
   "metadata": {},
   "source": [
    "Now before we get into making requests, we need to [subscribe to the API](https://rapidapi.com/clear-skies-clear-skies-default/api/papermill-alarm) and get an access key. The access key is essentially a password to use the API, so we shouldn't store it in the text of this notebook. That's not safe. So instead, we will make it into an environment variable. \n",
    "\n",
    "To do that, assuming you are using Windows, we will: \n",
    "- type 'env' into the search bar and you should see the option 'Edit the environment variables for your account'\n",
    "- click 'Environment Variables', 'New' and \n",
    "- enter 'PAPERMILL_ALARM_BATCH_KEY' as the \"Variable name\" and paste the key itself as the \"Variable value\".\n",
    "- Importantly, you will need to close this window, shut down the terminal running this notebook (with ctrl+c) and then restart the terminal for this change to take effect!\n",
    "\n",
    "Now we can use the code below to access our rapidapi key without making it visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24e0c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "rapidapi_key = os.environ.get('PAPERMILL_ALARM_BATCH_KEY')\n",
    "# this line just checks that the key exists\n",
    "# if you see 'assertion error', it means that we can't find the key. \n",
    "# Check you have the right name for it and then restart and try again.\n",
    "assert rapidapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea5a99",
   "metadata": {},
   "source": [
    "The rapidapi key will be passed to rapidapi via http headers. So let's define those now so that it's out of the way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95737e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'papermill-alarm.p.rapidapi.com'\n",
    "headers = {\n",
    "    'content-type':'application/json',\n",
    "    'X-RapidAPI-Key':rapidapi_key,\n",
    "    'X-RapidAPI-Host': url\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e81ea",
   "metadata": {},
   "source": [
    "Let's build a simple query function to query the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40ed0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f17584b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_papermill_alarm(doc):\n",
    "    # build the payload in the expected format\n",
    "    payload = {\"payload\":[doc]}\n",
    "    # define the URL endpoint that the papermill alarm uses\n",
    "    url = 'https://papermill-alarm.p.rapidapi.com'\n",
    "    # make a POST request to the API\n",
    "    r = requests.post(url, \n",
    "                      headers = headers,\n",
    "                      json = payload)\n",
    "    # if the response code is good, then we return the prediction\n",
    "    if r.status_code == 200:\n",
    "        return r.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff8260",
   "metadata": {},
   "source": [
    "Let's run the function on a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e678099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': [{'id': 'your_document_id',\n",
       "   'title': 'This is not a title of a paper',\n",
       "   'abstract': 'This is just an example piece of text. Not a real abstract.',\n",
       "   'message': {'status': 'green',\n",
       "    'message': 'We did not detect any features in this metadata which are consistent with paper-mill activity. However, this check is only a simple check of metadata and does not cover all known indicators of papermill activity.'}}],\n",
       " 'status_code': 200}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = {\"id\":\"your_document_id\",\n",
    "       \"title\":\"This is not a title of a paper\",\n",
    "       \"abstract\":\"This is just an example piece of text. Not a real abstract.\"}\n",
    "response = query_papermill_alarm(doc)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a4ebc",
   "metadata": {},
   "source": [
    "OK - so we can see the result for 1 document, but wouldn't it be better to have a way to put multiple documents through and analyse them? \n",
    "\n",
    "Let's load a large number of documents in the same format as the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11e699d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('arxiv_random_sample.json','r') as f:\n",
    "    arxiv_data = json.load(f)\n",
    "# check how many docs we have for testing\n",
    "len(arxiv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee094a76",
   "metadata": {},
   "source": [
    "Now, we simply pass those documents through our function to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27a8b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l,n):\n",
    "    \"\"\"We'll use this function to break the data into batches\"\"\"\n",
    "    for i in range(0,len(l),n):\n",
    "        yield l[i:(i+n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f17584b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_papermill_alarm_batch(batch):\n",
    "    # build the payload in the expected format\n",
    "    payload = {\"payload\":batch}\n",
    "    # define the URL endpoint that the papermill alarm uses\n",
    "    url = 'https://papermill-alarm.p.rapidapi.com'\n",
    "    # make a POST request to the API\n",
    "    r = requests.post(url, \n",
    "                      headers = headers,\n",
    "                      json = payload)\n",
    "    # if the response code is good, then we return the prediction\n",
    "    if r.status_code == 200:\n",
    "        return r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59051a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papermill Alarm is awake and working. Beginning to process docs!\n",
      "Response status code: 200\n",
      "PMA response: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:03<00:00,  6.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "## the wakeup function is just an ad hoc function which\n",
    "## ensures that the API is awake. Running the API is expensive, \n",
    "## so it automatically switches itself off.\n",
    "## This means that it's wise to wake it up before we make requests\n",
    "from wakeup import wakeup\n",
    "assert wakeup(headers=headers)\n",
    "\n",
    "## Now query the API\n",
    "results = []\n",
    "for batch in tqdm(list(chunks(arxiv_data,10))):\n",
    "    resp_data = query_papermill_alarm_batch(batch)\n",
    "    if resp_data and 'message' in resp_data:\n",
    "        results += resp_data['message']\n",
    "# check how many results we got\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe963ee",
   "metadata": {},
   "source": [
    "## Analyse this\n",
    "- let's just take a look at these predictions and see what we've got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bf96add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "green     99\n",
       "orange     1\n",
       "Name: alert, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def response_to_df(resp):\n",
    "    \"\"\"\n",
    "    Simply convert the response to a 1-deep dict so that we can\n",
    "    easily convert to dataframe\n",
    "    \"\"\"\n",
    "    return {'id':resp.get('id'),\n",
    "            'title':resp.get('title'),\n",
    "            'abstract':resp.get('abstract'),\n",
    "            'message':resp.get('message',dict()).get('message'),\n",
    "            'alert':resp.get('message',dict()).get('status')}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([response_to_df(resp) for resp in results])\n",
    "df.alert.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6bddc",
   "metadata": {},
   "source": [
    "That's weird. All of the articles we checked came back 'Green'. That's actually what we expect. The Papermill Alarm is trained on PubMed and so it is used to seeing papers in the biomedical fields. It isn't expecting to see physics, computer science and other ArXivy fields. \n",
    "\n",
    "You might consider this to be an 'out of domain' test. It's actually quite an important test, you see _because_ our API hasn't seen ArXiv before, we can't predict what it will do when it sees it. Now we know. Funnily enough, most of Pubmed will also come back Green. We are looking for quite a small signal in the grand scheme of things. \n",
    "\n",
    "## A better test\n",
    "Instead of looking for nothing, let's look for something and see if we can find that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3880d7",
   "metadata": {},
   "source": [
    "Then let's retrieve a different dataset. This is a list of retracted articles from [Smut Clyde's spreadsheets](https://docs.google.com/spreadsheets/d/1zKxfaqug4ZhwHyGzslF38pFyC8xtU8lzmmOFMGYITDI/edit#gid=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "516964cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sample_retractions.json','r') as f:\n",
    "    retractions = json.load(f)\n",
    "# check how many docs we have for testing\n",
    "len(retractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1641b65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papermill Alarm is awake and working. Beginning to process docs!\n",
      "Response status code: 200\n",
      "PMA response: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert wakeup(headers=headers)\n",
    "results = []\n",
    "for batch in tqdm(list(chunks(retractions,10))):\n",
    "    resp_data = query_papermill_alarm_batch(batch)\n",
    "    if 'message' in resp_data:\n",
    "        results += resp_data['message']\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78dfa9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "red       30\n",
       "orange     1\n",
       "Name: alert, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([response_to_df(resp) for resp in results])\n",
    "df.alert.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fcbf9",
   "metadata": {},
   "source": [
    "And there we are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bcefe8d1e3fdc297f6ceed70ea8aa07f35fd56443053774805f2f5691056b50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
