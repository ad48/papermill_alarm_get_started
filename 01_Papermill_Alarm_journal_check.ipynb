{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32157eae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Papermill Alarm template analysis\n",
    "\n",
    "This is a simple analysis notebook for use with the Papermill Alarm. It will allow you to identify journals and special volumes/issues that may have been targeted by papermills in the past. \n",
    "\n",
    "It's important to re-iterate that the Papermill Alarm only detects similarity between a paper and other papers which are believed to have been created by paper mills. It is not evidence of misconduct in itself and should be thought of as an indication of where to look carefully for that evidence. \n",
    "\n",
    "The processes below will help you to find papermill content in published literature using OpenAlex. There is plenty of scope to adapt the process here to any specific problem. \n",
    "\n",
    "E.g. \n",
    "- instead of reading data from OpenAlex, you could read data from new submissions and run them through the same process. This might help you identify papermill submissions before peer-review. \n",
    "- instead of looking at a selection of ISSNs, you could just look at a whole publisher. This would mean adapting the OpenAlex query\n",
    "\n",
    "### Before we begin. Prerequisites.\n",
    "1. This does require some experience of Python\n",
    "2. you will need 2 environment variables\n",
    "    - __PAPERMILL_ALARM_BATCH_KEY__ (this is the API key for the BATCH version of the papermill alarm which you can get from RapidAPI)\n",
    "    - __MY_EMAIL__ (this is your email address which will get sent to OpenAlex with your queries. This way, if you send too many queries and it is a problem for them, they can email you to ask you to stop. Including your email address is optional, BUT if you don't include it, OpenAlex might give you slower responses. [See their docs for details](https://docs.openalex.org/api).)\n",
    "    - after creating the environment variables, you will need to restart whichever terminal you launched this notebook from.\n",
    "3. Then you will need to step through this notebook one cell at a time. Sometimes you will need to edit cells to update variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5126eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d180f51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Before we start, import all the packages we will need\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2265b56",
   "metadata": {},
   "source": [
    "## Start by defining the journals we want to study\n",
    "- we'll make a name for our study and this will automatically get translated into the name of a data directory where data will be stored.\n",
    "- update the variables below to have the issn of the journal(s) we want to look at\n",
    "- then you might want to update the path variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d51351",
   "metadata": {},
   "source": [
    "# Example\n",
    "I managed the peer-review operations for a gravitational physics journal from 2009-2015. This is a subject area, and an era, where I wouldn't expect to see any papermilling going on. But I am curious to see!\n",
    "\n",
    "Furthermore, the Papermill Alarm (v1) was trained on PubMed. This means that this is another _out of domain_ test. We don't expect to find anything, but we won't know until we check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021631c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the ISSN of the journal you want to study\n",
    "# this cell will create a folder in your D drive for it \n",
    "# If you don't want to use the D drive, change 'data_dir' to a path of your choice\n",
    "# once you have finished editing this cell, delete the line containing 'assert False'\n",
    "STUDY_NAME = 'Gravitational Physics'\n",
    "ISSNS = ['0264-9381', '1572-9532', '2470-0029', ] # ISSNs of journals in this area\n",
    "YEARS = list(range(2009,2016)) # equivalent to saying 'lets look at every year from 2009 to 2016 (but not including 2016!)\n",
    "DATA_DIR = os.path.abspath(f'D:\\\\Papermill_alarm_study_{STUDY_NAME}')\n",
    "DATASET_P = os.path.join(DATA_DIR, f'journal_openalex_data_{STUDY_NAME}.json')\n",
    "RESULTS_P = os.path.join(DATA_DIR, f'papermill_alarm_results_{STUDY_NAME}.json')\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e128f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check to see if your data directory already exists\n",
    "## if not, create it.\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42b188",
   "metadata": {},
   "source": [
    "## Environment variables\n",
    "- we need environment variables for the Papermill Alarm API key AND for our email address. \n",
    "\n",
    "This email address will be sent to OpenAlex with our queries so that they know who to contact if the queries cause problems for their API. You can simply send an empty string if you want to query OpenAlex anonymously, but then you will get slower responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e301d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = os.environ.get('MY_EMAIL')\n",
    "## this will throw an error if you haven't defined an email address properly\n",
    "## you can set email='' to access OpenAlex anonymously, but sending your email address is recommended\n",
    "assert email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5425099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the API key\n",
    "rapidapi_key = os.environ.get('PAPERMILL_ALARM_BATCH_KEY')\n",
    "# this line just checks that the key exists\n",
    "# if you see 'assertion error', it means that we can't find the key. \n",
    "# Check you have created the environment variable and then restart and try again.\n",
    "assert rapidapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fa6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://papermill-alarm.p.rapidapi.com'\n",
    "headers = {\n",
    "    'content-type':'application/json',\n",
    "    'X-RapidAPI-Key':rapidapi_key,\n",
    "    'X-RapidAPI-Host': 'papermill-alarm.p.rapidapi.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b2ba4",
   "metadata": {},
   "source": [
    "# Acquire data\n",
    "We will download all of the data for the ISSNs we chose above.\n",
    "\n",
    "The code below will first import some ad hoc functions for accessing OpenAlex's API\n",
    "\n",
    "Then we will check to see if the data has already been downloaded. \n",
    "- if not, we download it\n",
    "- if so, we simply load it from file (much faster!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c90f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openalex import openalex_from_issn, abstract_from_oa_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d1e42a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47971"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does our dataset exist?\n",
    "if not os.path.exists(DATASET_P):            \n",
    "    # if not, we'll download everything \n",
    "    all_jnl_data = []\n",
    "    for issn in ISSNS:\n",
    "        print(f'Retrieving data for {issn}')\n",
    "        for data in tqdm(openalex_from_issn(issn, email)):\n",
    "            all_jnl_data += data\n",
    "    # then save it to file\n",
    "    with open(DATASET_P, 'w') as f:\n",
    "        json.dump(all_jnl_data,f)\n",
    "else:\n",
    "    # if our dataset DOES exist, we just load it\n",
    "    with open(DATASET_P, 'r') as f:\n",
    "        all_jnl_data = json.load(f)\n",
    "        \n",
    "        \n",
    "len(all_jnl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ec2b4",
   "metadata": {},
   "source": [
    "# Check the data\n",
    "\n",
    "\n",
    "Before we proceed, we need to check that the data we have from OpenAlex is suitable for the task. \n",
    "\n",
    "We'll quickly audit the data to check for\n",
    "- missing data. We need titles, abstracts and unique IDs for each document.\n",
    "- duplication. In case we accidentally downloaded the same document twice - no point in querying the papermill alarm twice when we only need to do it once.\n",
    "- any obviously unclean text that we might be able to fix. A title might not be missing, but it might indicate that the article is not a research article e.g. 'preface' or 'editorial'\n",
    "\n",
    "# Then clean (filter) the data\n",
    "\n",
    "Our checks will dictate changes that we can make to improve the data quality. This might include:\n",
    "\n",
    "- remove any data that can't be fixed\n",
    "- limit the data to whatever we're interested in. E.g. recent dates only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810f398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAlex data comes in structured JSON format.\n",
    "## This is great, but it would be easier to work\n",
    "## with a tabular format. So we'll convert\n",
    "## the OpenAlex documents into DataFrame rows.\n",
    "## DataFrames are like Excel, except good.\n",
    "def convert_doc(doc):\n",
    "    \"Flatten an openalex doc into a dataframe row\"\n",
    "    return {\n",
    "        'id':doc.get('id'),\n",
    "        'title':doc.get('title'),\n",
    "        'abstract':abstract_from_oa_response(doc),\n",
    "        'publication_year':doc.get('publication_year'),\n",
    "        'publication_date':doc.get('publication_date'),\n",
    "        'volume':doc.get('biblio',{}).get('volume'),\n",
    "        'issue':doc.get('biblio',{}).get('issue'),\n",
    "        'issn_l':doc.get('issn_l'),\n",
    "        'journal':doc.get('host_venue',{}).get('display_name'),\n",
    "        'publisher':doc.get('host_venue',{}).get('publisher'),\n",
    "        'is_retracted':doc.get('is_retracted')\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90c1ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47971, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, I'll convert the data into a temporary dataframe to make it a bit more friendly\n",
    "dftmp = pd.DataFrame([convert_doc(doc) for doc in all_jnl_data])\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03875fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    4856\n",
       "2020    4527\n",
       "2019    4278\n",
       "2018    4158\n",
       "2016    4152\n",
       "2017    4015\n",
       "2022    3315\n",
       "2004     843\n",
       "1989     823\n",
       "2009     741\n",
       "2003     720\n",
       "2006     718\n",
       "2002     712\n",
       "2005     710\n",
       "2010     707\n",
       "2011     703\n",
       "2008     699\n",
       "2014     659\n",
       "2007     638\n",
       "2013     635\n",
       "2015     631\n",
       "2012     601\n",
       "2001     579\n",
       "2000     563\n",
       "1997     525\n",
       "1999     490\n",
       "1996     456\n",
       "1993     445\n",
       "1998     443\n",
       "1994     408\n",
       "1992     399\n",
       "1990     390\n",
       "1995     375\n",
       "1977     356\n",
       "1991     332\n",
       "1987     330\n",
       "1988     304\n",
       "1986     242\n",
       "1985     218\n",
       "1984     196\n",
       "1979     166\n",
       "1983     133\n",
       "1982     112\n",
       "1981     105\n",
       "1978      99\n",
       "1976      98\n",
       "1980      90\n",
       "1974      63\n",
       "1975      62\n",
       "1971      50\n",
       "1972      42\n",
       "1973      39\n",
       "1970      20\n",
       "Name: publication_year, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many articles are present for each year?\n",
    "dftmp['publication_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8258f8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4677, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the data just to the years that we specified at the start\n",
    "dftmp = dftmp[dftmp['publication_year'].isin(set(YEARS))]\n",
    "# check the shape - how much data is left after this filter?\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea231fc",
   "metadata": {},
   "source": [
    "#### Check for missing abstracts\n",
    "\n",
    "Usually there are SOME missing abstracts, so we might see the number of 'non-null' entries here as being lower for abstracts than for, say, titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f28ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4677 entries, 0 to 47967\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                4677 non-null   object\n",
      " 1   title             4677 non-null   object\n",
      " 2   abstract          4512 non-null   object\n",
      " 3   publication_year  4677 non-null   int64 \n",
      " 4   publication_date  4677 non-null   object\n",
      " 5   volume            1902 non-null   object\n",
      " 6   issue             1900 non-null   object\n",
      " 7   issn_l            0 non-null      object\n",
      " 8   journal           4677 non-null   object\n",
      " 9   publisher         4662 non-null   object\n",
      " 10  is_retracted      4677 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(9)\n",
      "memory usage: 406.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dftmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f000ba6",
   "metadata": {},
   "source": [
    "How many non-null values do we have?\n",
    "\n",
    "Remember, we need title, abstract and id. Are there enough non-null values for abstract? Abstracts are sometimes missing in OpenAlex. \n",
    "\n",
    "If there are missing abstracts, we might want to try a different data source if possible. Missing abstracts can severely limit what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48086884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are missing abstracts?\n",
    "dftmp['abstract_missing'] = dftmp['abstract'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1d90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>abstract_missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journal</th>\n",
       "      <th>volume</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Classical and Quantum Gravity</th>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">General Relativity and Gravitation</th>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Physical review</th>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           abstract_missing\n",
       "journal                            volume                  \n",
       "Classical and Quantum Gravity      21                     0\n",
       "                                   23                     0\n",
       "                                   26                    16\n",
       "                                   27                    16\n",
       "                                   28                    12\n",
       "                                   29                    10\n",
       "                                   30                     7\n",
       "                                   31                     8\n",
       "                                   32                     0\n",
       "                                   33                     0\n",
       "                                   34                     0\n",
       "                                   38                     0\n",
       "General Relativity and Gravitation 40                     0\n",
       "                                   41                     6\n",
       "                                   42                     7\n",
       "                                   43                     5\n",
       "                                   44                     3\n",
       "                                   45                     3\n",
       "                                   46                     2\n",
       "                                   47                     0\n",
       "                                   48                     0\n",
       "                                   49                     0\n",
       "                                   51                     0\n",
       "Physical review                    93                     0\n",
       "                                   94                     0\n",
       "                                   95                     0\n",
       "                                   96                     0\n",
       "                                   98                     0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if we are looking at volumes / issues,\n",
    "## manually check volume / issues to see if the abstracts are missing at that level\n",
    "## e.g. if it's a special issues journal is it just that sometimes abstracts don't get submitted for a whole issue/volume?\n",
    "dftmp[['journal','volume','abstract_missing']].groupby(['journal','volume']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34bd06fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>issn_l</th>\n",
       "      <th>journal</th>\n",
       "      <th>publisher</th>\n",
       "      <th>is_retracted</th>\n",
       "      <th>abstract_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22086</th>\n",
       "      <td>https://openalex.org/W4239490462</td>\n",
       "      <td>1949–2011 Sixty-Two Years Gravity Research Fou...</td>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>General Relativity and Gravitation</td>\n",
       "      <td>Springer Nature</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20251</th>\n",
       "      <td>https://openalex.org/W1480699288</td>\n",
       "      <td>Giorgio Ferrarese, Donato Bini: Introduction t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-02-01</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>General Relativity and Gravitation</td>\n",
       "      <td>Springer Nature</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14316</th>\n",
       "      <td>https://openalex.org/W4240682702</td>\n",
       "      <td>LISA 8 Science Organizing Committee and Local ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-04-19</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>Classical and Quantum Gravity</td>\n",
       "      <td>IOP Publishing</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "22086  https://openalex.org/W4239490462   \n",
       "20251  https://openalex.org/W1480699288   \n",
       "14316  https://openalex.org/W4240682702   \n",
       "\n",
       "                                                   title abstract  \\\n",
       "22086  1949–2011 Sixty-Two Years Gravity Research Fou...     None   \n",
       "20251  Giorgio Ferrarese, Donato Bini: Introduction t...     None   \n",
       "14316  LISA 8 Science Organizing Committee and Local ...     None   \n",
       "\n",
       "       publication_year publication_date volume issue issn_l  \\\n",
       "22086              2010       2010-06-29     42    12   None   \n",
       "20251              2009       2009-02-01     41     2   None   \n",
       "14316              2011       2011-04-19     28     9   None   \n",
       "\n",
       "                                  journal        publisher  is_retracted  \\\n",
       "22086  General Relativity and Gravitation  Springer Nature         False   \n",
       "20251  General Relativity and Gravitation  Springer Nature         False   \n",
       "14316       Classical and Quantum Gravity   IOP Publishing         False   \n",
       "\n",
       "       abstract_missing  \n",
       "22086              True  \n",
       "20251              True  \n",
       "14316              True  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## manually check individual articles with missing abstracts\n",
    "## should the data be here?\n",
    "dftmp[dftmp['abstract'].isna()].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3abb2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 12)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## either way, let's drop all rows with missing abstracts\n",
    "dftmp = dftmp[~dftmp['abstract'].isna()]\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb823625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 12)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sometimes we have generic titles which appear multiple times. \n",
    "## these are usually 'Preface' or 'Editorial' etc. We can probably drop these.\n",
    "maximum_times_a_title_can_appear = 1\n",
    "dftmp = dftmp[dftmp['title'].isin(set((dftmp['title'].value_counts()>maximum_times_a_title_can_appear).index))]\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09e6bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4513, 12)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now drop any duplicates\n",
    "dftmp = dftmp.drop_duplicates('id', keep = 'first')\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955947ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f868130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## manually look at some errors\n",
    "# [doc for doc in formatted_docs if not all([len(str(doc.get('id')))>4, len(str(doc.get('title')))>4,len(str(doc.get('abstract')))>4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "349d01cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4401, 12)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out docs with unusually short titles/abstracts\n",
    "\n",
    "def check_str_len(s,n):\n",
    "    # min n words in str\n",
    "    s = str(s) # coerce to str - prefer that this is done upstream, but this fn will filter problematic rows anyway\n",
    "    # then split the string into words and check that there are more than n\n",
    "    return len(s.split())>n\n",
    "\n",
    "min_title_length = 3\n",
    "min_abstract_length = 10\n",
    "\n",
    "dftmp = dftmp[(dftmp['title'].map(lambda x: check_str_len(x,min_title_length))) & (dftmp['abstract'].map(lambda x: check_str_len(x,min_abstract_length)))]\n",
    "dftmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53da32b",
   "metadata": {},
   "source": [
    "# Now for the fun part\n",
    "- let's query the Papermill Alarm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94926543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import our ad hoc function to check that the papermill alarm is awake\n",
    "from wakeup import wakeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27a8b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this simple function turns a list into a list of lists\n",
    "# it's basically a way to convert our data into batches\n",
    "def chunks(l,n):\n",
    "    for i in range(0,len(l),n):\n",
    "        yield l[i:(i+n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cff75695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_papermill_alarm(doc_batch):\n",
    "    # build the payload in the expected format\n",
    "    payload = {\"payload\":doc_batch}\n",
    "    # define the URL endpoint that the papermill alarm uses\n",
    "    url = 'https://papermill-alarm.p.rapidapi.com'\n",
    "    # make a POST request to the API\n",
    "    r = requests.post(url, \n",
    "                      headers = headers,\n",
    "                      json = payload)\n",
    "    # if the response code is good, then we return the prediction\n",
    "    if r.status_code == 200:\n",
    "        resp_data = r.json()\n",
    "        return resp_data.get('message',[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7697799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4401"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = set(dftmp['id'])\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79448863",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e86db3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have 4401 documents still to query with the Papermill Alarm.\n"
     ]
    }
   ],
   "source": [
    "ids_found = set()\n",
    "results = []\n",
    "n=10\n",
    "\n",
    "# check to see if we already ran this search\n",
    "if os.path.exists(RESULTS_P):            \n",
    "    with open(RESULTS_P, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    ids_found = {x['id'] for x in results}\n",
    "\n",
    "# if we already ran the search, let's drop all the ids that we already found\n",
    "ids_to_find = {x for x in ids if x not in ids_found}\n",
    "print(f'We still have {len(ids_to_find)} documents still to query with the Papermill Alarm.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e311a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 4401 documents...\n"
     ]
    }
   ],
   "source": [
    "# then we can just search for the remaining ids\n",
    "dftmp = dftmp[dftmp['id'].isin(ids_to_find)]\n",
    "## limit to the columns we need \n",
    "dftmp= dftmp[['id','title','abstract']]\n",
    "# now just get the rows as json docs\n",
    "formatted_docs = list(dftmp.T.to_dict().values())\n",
    "\n",
    "print(f'Checking {len(formatted_docs)} documents...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f08657d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 500\n",
      "PMA response: None\n",
      "Papermill Alarm needs time to wake up. Waiting for 60s.\n",
      "Response status code: 504\n",
      "PMA response: None\n",
      "Papermill Alarm needs time to wake up. Waiting for 60s.\n",
      "Response status code: 504\n",
      "PMA response: None\n",
      "Papermill Alarm needs time to wake up. Waiting for 60s.\n",
      "Papermill Alarm is awake and working. Beginning to process docs!\n",
      "Response status code: 200\n",
      "PMA response: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [44:33<00:00,  6.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4401"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(formatted_docs)>0:\n",
    "    # wake up the papermill alarm\n",
    "    awake = wakeup(headers=headers)\n",
    "    assert awake\n",
    "    # here we perform the search\n",
    "    for doc_batch in tqdm(chunks(formatted_docs,n), total = 1+(len(formatted_docs)//n)):\n",
    "        results += query_papermill_alarm(doc_batch)\n",
    "\n",
    "    # and write out the results\n",
    "    with open(RESULTS_P, 'w') as f:\n",
    "        json.dump(results,f)\n",
    "    \n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4af31d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "green     4395\n",
       "orange       6\n",
       "Name: alert, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def response_to_df(resp):\n",
    "    \"\"\"\n",
    "    Simply convert the response to a 1-deep dict so that we can\n",
    "    easily convert to dataframe\n",
    "    \"\"\"\n",
    "    return {'id':resp.get('id'),\n",
    "            'title':resp.get('title'),\n",
    "            'abstract':resp.get('abstract'),\n",
    "            'message':resp.get('message',dict()).get('message'),\n",
    "            'alert':resp.get('message',dict()).get('status')}\n",
    "\n",
    "df = pd.DataFrame([response_to_df(resp) for resp in results])\n",
    "df.alert.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8978f",
   "metadata": {},
   "source": [
    "## Findings\n",
    "We're seeing 4395 green alerts (nothing to worry about) and 6 'orange' alerts which are essentially red alerts with low-confidence (you can usually ignore orange alerts). \n",
    "\n",
    "Since we already know that we are unlikely to find any papermill-products in this area, this is in-line with expectations. It's reasonable to conclude that the small number of orange alerts represent a low false-positive rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1377587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>message</th>\n",
       "      <th>alert</th>\n",
       "      <th>suspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>https://openalex.org/W2005674598</td>\n",
       "      <td>An alternative well-posedness property and sta...</td>\n",
       "      <td>In the first part of this paper, we show that ...</td>\n",
       "      <td>This article has SOME features in common with ...</td>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>https://openalex.org/W2067816691</td>\n",
       "      <td>Hawking radiation of charged rotating AdS blac...</td>\n",
       "      <td>Extending researches on Hawking radiation to c...</td>\n",
       "      <td>This article has SOME features in common with ...</td>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>https://openalex.org/W1985871997</td>\n",
       "      <td>Fluid/gravity correspondence for general non-r...</td>\n",
       "      <td>In this paper, we investigate the fluid/gravit...</td>\n",
       "      <td>This article has SOME features in common with ...</td>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "2762  https://openalex.org/W2005674598   \n",
       "3556  https://openalex.org/W2067816691   \n",
       "950   https://openalex.org/W1985871997   \n",
       "\n",
       "                                                  title  \\\n",
       "2762  An alternative well-posedness property and sta...   \n",
       "3556  Hawking radiation of charged rotating AdS blac...   \n",
       "950   Fluid/gravity correspondence for general non-r...   \n",
       "\n",
       "                                               abstract  \\\n",
       "2762  In the first part of this paper, we show that ...   \n",
       "3556  Extending researches on Hawking radiation to c...   \n",
       "950   In this paper, we investigate the fluid/gravit...   \n",
       "\n",
       "                                                message   alert  suspect  \n",
       "2762  This article has SOME features in common with ...  orange        1  \n",
       "3556  This article has SOME features in common with ...  orange        1  \n",
       "950   This article has SOME features in common with ...  orange        1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at some alerts at random\n",
    "df[df['alert']=='orange'].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4734651",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_of_interest = {'red','orange'} # 'red' alerts are high similarity to past papermills, 'orange' have lower similarity\n",
    "\n",
    "# label alerts as 'suspect'. \n",
    "df['suspect'] = [1  if x in alerts_of_interest else 0 for x in df['alert'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba7c2c",
   "metadata": {},
   "source": [
    "# These next few cells are to help explore cases where we DO find something. \n",
    "- results below here aren't likely to be meaningful in cases where we don't have red alerts. \n",
    "- I'm leaving the code here for anyone who wants to play around with it on a different dataset. \n",
    "\n",
    "### Merge with original dataset to get volume and issue numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f89351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4402, 14)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now merge the openalex data with our predictions\n",
    "right =  pd.DataFrame([convert_doc(doc) for doc in all_jnl_data])\n",
    "adf = df[['id','message','alert','suspect']].merge(right = right, on='id', how = 'left')\n",
    "adf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88865c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f48335",
   "metadata": {},
   "source": [
    "#### Check for articles that are already retracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "649bd7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## number of retractions recorded by openalex\n",
    "right['is_retracted'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "932c8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right[right['is_retracted']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "166de0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>alert</th>\n",
       "      <th>suspect</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>issn_l</th>\n",
       "      <th>journal</th>\n",
       "      <th>publisher</th>\n",
       "      <th>is_retracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, message, alert, suspect, title, abstract, publication_year, publication_date, volume, issue, issn_l, journal, publisher, is_retracted]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## quick and dirty check for retracted articles\n",
    "adf[adf['title'].map(lambda x: any(substr in x for substr in {'retract', 'expression of concern'})) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b07b7",
   "metadata": {},
   "source": [
    "## Check for journals / volumes /issues that may have been targeted\n",
    "- depending on whether you think papermills are getting in through specific journals or through special issues, set the 'target_level' variable to 'journal','volume' or 'issue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dda38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_level = 'journal' # 'volume' # 'issue'\n",
    "\n",
    "gb = adf[[target_level,'suspect']].groupby([target_level]).sum().sort_values('suspect',ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fea8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if we have used a target level like 'volume' or 'issue', we can check to see\n",
    "## if we have some issues that stand out.\n",
    "# gb.suspect.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3654b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d307be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>alert</th>\n",
       "      <th>suspect</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>issn_l</th>\n",
       "      <th>journal</th>\n",
       "      <th>publisher</th>\n",
       "      <th>is_retracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, message, alert, suspect, title, abstract, publication_year, publication_date, volume, issue, issn_l, journal, publisher, is_retracted]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_names = {'journal_name'}\n",
    "adf[(adf['journal'].isin(journal_names))*(adf['alert']!='green')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cac0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bcefe8d1e3fdc297f6ceed70ea8aa07f35fd56443053774805f2f5691056b50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
